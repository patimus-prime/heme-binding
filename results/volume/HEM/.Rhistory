# WITH THE REGEXP '.pdb' in the folder!!!! this will throw errors!
# now still throws an error but minor. I think it doesn't like the source dataframe only having 1 column
#source("~/heme-binding/scripts/r/metal_coordination.R") #garbage
# ok let's reorder
# DECLARATIONS --------------
ligandList = list("HEM")#,"HEC","SRM","VER","VEA")
angstromDistance = 7.0 #not sure if used here, maybe useful for figures!
# Initialize list of DFs/lists, add results in each for loop
# FIXME! The automated naming doesn't like this lol, for lists in particular
# moving ahead with fixed results and merging in a few steps.
# shitty list code in VOLUME for loop
# need a different loop for each script, as the result paths are different for all
#------ VOLUME ---------
source("~/heme-binding/scripts/r/volume.R")
resultPath = "~/heme-binding/results/volume/"
for(ligand in 1:(length(ligandList)))
{
activeLigand = ligandList[[ligand]]
activeResultPath = paste(resultPath,activeLigand,sep = "")
volume_dfs <- volumeFn(activeLigand,activeResultPath)
#this line is freaky fresh
# paste() automates df name creation, second arg is the df assigned. BAM!
assign(paste(activeLigand,"_maxVolDf",sep=""), volume_dfs$maxVolDf)
#eval(parse(text=(paste(activeLigand,"_dfList",sep = "")))) <- list(volume_dfs$maxVolDf, volume_dfs$allVolDf)
# xx <- list(volume_dfs$maxVolDf)
#  eval(parse(text = paste(activeLigand,"_dfList",sep = ""))) <- xx
# "yy" = list(volume_dfs$allVolDf)
}
volume_dfs <- volumeFn(activeLigand,activeResultPath)
# volume_dfs <- volumeFn(activeLigand,activeResultPath)
rrrt <- volumeFn(activeLigand,activeResultPath)
# This is the main R file for this project. Launches other scripts used
library(dplyr)
library(data.table)
library(tidyr)
library(ggplot2) #thus far not used 22 June 2021
library(stringr)
source("~/heme-binding/scripts/r/addpdbcol.R")
#source("C:/Users/nobody/Documents/R/MyScript.R")
# for the pdb-Titles_codes script, YOU MUST NOT HAVE ANYTHING THAT COULD INTERFERE
# WITH THE REGEXP '.pdb' in the folder!!!! this will throw errors!
# now still throws an error but minor. I think it doesn't like the source dataframe only having 1 column
#source("~/heme-binding/scripts/r/metal_coordination.R") #garbage
# ok let's reorder
# DECLARATIONS --------------
ligandList = list("HEM")#,"HEC","SRM","VER","VEA")
angstromDistance = 7.0 #not sure if used here, maybe useful for figures!
# Initialize list of DFs/lists, add results in each for loop
# FIXME! The automated naming doesn't like this lol, for lists in particular
# moving ahead with fixed results and merging in a few steps.
# shitty list code in VOLUME for loop
# need a different loop for each script, as the result paths are different for all
#------ VOLUME ---------
source("~/heme-binding/scripts/r/volume.R")
resultPath = "~/heme-binding/results/volume/"
for(ligand in 1:(length(ligandList)))
{
activeLigand = ligandList[[ligand]]
activeResultPath = paste(resultPath,activeLigand,sep = "")
volume_dfs <- volumeFn(activeLigand,activeResultPath)
#rrrt <- volumeFn(activeLigand,activeResultPath)
#this line is freaky fresh
# paste() automates df name creation, second arg is the df assigned. BAM!
assign(paste(activeLigand,"_maxVolDf",sep=""), volume_dfs$maxVolDf)
#eval(parse(text=(paste(activeLigand,"_dfList",sep = "")))) <- list(volume_dfs$maxVolDf, volume_dfs$allVolDf)
# xx <- list(volume_dfs$maxVolDf)
#  eval(parse(text = paste(activeLigand,"_dfList",sep = ""))) <- xx
# "yy" = list(volume_dfs$allVolDf)
}
library(dplyr)
library(data.table)
library(tidyr)
library(ggplot2) #thus far not used 22 June 2021
source("~/heme-binding/scripts/r/addpdbcol.R")
#volumeFn <- function(activeLigand, activeResultPath)
#{
activeLigand = "HEM"
#for filtering: https://www.youtube.com/watch?v=PsSqn0pxouM
paste(activeLigand,"Volume data processing...")
# 0. Notes on global variables...---------------------------
#may need to specify this option every run/change for running ALL PROCESSED FILES
#options(max.print = 999999999999999999999) #or whatever number
# 1. Assembling all results into one dataframe -----------------------------
#set working directory to the folder w files!
#setwd("~/heme-binding/results/volume")
setwd(activeResultPath)
# import all the shit that's been processed
# currently using results specific file, all of type .txt; therefore:
result_files_ls <- list.files(pattern = "*.txt")
# may need to add path = whatever from wd into the parentheses
# result_files_ls is now a list of all the fuckin txt files
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {read.delim(file = x, header = FALSE)})
# add source pdb column
result_files_df <- addpdbcol(result_files_df)
#i think each file now has its own dataframe. now we combine them
combined_results_df <- do.call("rbind", lapply(result_files_df, as.data.frame))
#@ line 981 (w/ orig PDBs, get an enormous volume. can either throw out this header, or filter as below)
# combined_results_df is now the final output of this section and the primary df
# 2. Volume Data ------------------------------------------
# get only the REAL, INDIV VOLUMES ACQUIRED!!!
# remove the sum volume
combined_results_df %>%
filter(grepl('[?]', V1)) -> combined_results_df
# acquire only the numeric data
combined_results_df %>%
separate(V1, c(NA ,"volume_data"), "volume = ") -> volume_data_df
# 3. Filter ------------
# remove the NA values from the dataframe (this is a result of rows that did not contain volume data)
volume_data_clean <- na.omit(volume_data_df)
volume_data_df <- volume_data_clean
# shit was imported from the text file as strings, convert to numbers
volume_data_df$volume_data <- as.numeric(as.character(volume_data_df$volume_data))
# remove outliers ----------
# outlier operation however FUCKS IT UP so... need to convert back to df in between ops
# therefore, below code filters >50, conv back to df, filter <= 1000, conv back to df
volume_data_df <- volume_data_df[volume_data_df$volume_data >= 50, ]
volume_data_df <- as.data.frame(volume_data_df)
#volume_data_df <- volume_data_df[volume_data_df$volume_data <= 1000, ]
#volume_data_df <- as.data.frame(volume_data_df)
# selecting only the max for each row
volume_data_df %>%
group_by(PDB_ID) %>% slice(which.max(volume_data)) -> max_volume_df
##group %>% group_by(sub) %>% slice(which.max(marks))
# from: https://www.geeksforgeeks.org/how-to-select-row-with-maximum-value-in-each-group-in-r-language/
# 4. VOLUME DATA PLOT! -----------------
# moved to main!
# hist(volume_data_df$volume_data,
#      main = "Distribution of Volume of Pockets",
#      xlab = "Volume, A3",
#      col = "darkmagenta",
#      xlim = c(50,600), #force start at 50 then go to 1000
#      #breaks = c(0,100,150,200,250,300,350,400,450,1000)
#      )
#
#
# 99. Cleanup! ----------
# rm(result_files_df,
#    combined_results_df,
#    temp_df,
#    volume_data_clean,
#    no_quest,
#    line_w_code
#
# )
# return data ----------
#return stuff ----------
volumeDataframes <- list(
"allVolDf" = volume_data_df,
"maxVolDf" = max_volume_df
)
# return(volumeDataframes)
#return(max_volume_df)
#}
library(dplyr)
library(data.table)
library(tidyr)
library(ggplot2) #thus far not used 22 June 2021
source("~/heme-binding/scripts/r/addpdbcol.R")
#volumeFn <- function(activeLigand, activeResultPath)
#{
activeLigand = "HEM"
#for filtering: https://www.youtube.com/watch?v=PsSqn0pxouM
paste(activeLigand,"Volume data processing...")
# 0. Notes on global variables...---------------------------
#may need to specify this option every run/change for running ALL PROCESSED FILES
#options(max.print = 999999999999999999999) #or whatever number
# 1. Assembling all results into one dataframe -----------------------------
#set working directory to the folder w files!
#setwd("~/heme-binding/results/volume")
setwd(activeResultPath)
# import all the shit that's been processed
# currently using results specific file, all of type .txt; therefore:
result_files_ls <- list.files(pattern = "*.txt")
# may need to add path = whatever from wd into the parentheses
# result_files_ls is now a list of all the fuckin txt files
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {read.delim(file = x, header = FALSE)})
# add source pdb column
result_files_df <- addpdbcol(result_files_df)
#i think each file now has its own dataframe. now we combine them
combined_results_df <- do.call("rbind", lapply(result_files_df, as.data.frame))
#@ line 981 (w/ orig PDBs, get an enormous volume. can either throw out this header, or filter as below)
# combined_results_df is now the final output of this section and the primary df
# 2. Volume Data ------------------------------------------
# get only the REAL, INDIV VOLUMES ACQUIRED!!!
# remove the sum volume
combined_results_df %>%
filter(grepl('[?]', V1)) -> combined_results_df
# acquire only the numeric data
combined_results_df %>%
separate(V1, c(NA ,"volume_data"), "volume = ") -> volume_data_df
# 3. Filter ------------
# remove the NA values from the dataframe (this is a result of rows that did not contain volume data)
volume_data_clean <- na.omit(volume_data_df)
volume_data_df <- volume_data_clean
# shit was imported from the text file as strings, convert to numbers
volume_data_df$volume_data <- as.numeric(as.character(volume_data_df$volume_data))
# remove outliers ----------
# outlier operation however FUCKS IT UP so... need to convert back to df in between ops
# therefore, below code filters >50, conv back to df, filter <= 1000, conv back to df
volume_data_df <- volume_data_df[volume_data_df$volume_data >= 50, ]
volume_data_df <- as.data.frame(volume_data_df)
#volume_data_df <- volume_data_df[volume_data_df$volume_data <= 1000, ]
#volume_data_df <- as.data.frame(volume_data_df)
# selecting only the max for each row
volume_data_df %>%
group_by(PDB_ID) %>% slice(which.max(volume_data)) -> max_volume_df
##group %>% group_by(sub) %>% slice(which.max(marks))
# from: https://www.geeksforgeeks.org/how-to-select-row-with-maximum-value-in-each-group-in-r-language/
# 4. VOLUME DATA PLOT! -----------------
# moved to main!
# hist(volume_data_df$volume_data,
#      main = "Distribution of Volume of Pockets",
#      xlab = "Volume, A3",
#      col = "darkmagenta",
#      xlim = c(50,600), #force start at 50 then go to 1000
#      #breaks = c(0,100,150,200,250,300,350,400,450,1000)
#      )
#
#
# 99. Cleanup! ----------
# rm(result_files_df,
#    combined_results_df,
#    temp_df,
#    volume_data_clean,
#    no_quest,
#    line_w_code
#
# )
# return data ----------
#return stuff ----------
volumeDataframes <- list(
"allVolDf" = volume_data_df,
"maxVolDf" = max_volume_df
)
# return(volumeDataframes)
#return(max_volume_df)
#}
iconv file.pcl -f UTF-8 -t ISO-8859-1 -c
iconv file.pcl -f UTF-8 -t ISO-8859-1 -c
library(dplyr)
library(data.table)
library(tidyr)
library(ggplot2) #thus far not used 22 June 2021
source("~/heme-binding/scripts/r/addpdbcol.R")
#volumeFn <- function(activeLigand, activeResultPath)
#{
activeLigand = "HEM"
#for filtering: https://www.youtube.com/watch?v=PsSqn0pxouM
paste(activeLigand,"Volume data processing...")
# 0. Notes on global variables...---------------------------
#may need to specify this option every run/change for running ALL PROCESSED FILES
#options(max.print = 999999999999999999999) #or whatever number
# 1. Assembling all results into one dataframe -----------------------------
#set working directory to the folder w files!
#setwd("~/heme-binding/results/volume")
setwd(activeResultPath)
# import all the shit that's been processed
# currently using results specific file, all of type .txt; therefore:
result_files_ls <- list.files(pattern = "*.txt")
# may need to add path = whatever from wd into the parentheses
# result_files_ls is now a list of all the fuckin txt files
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {read.delim(file = x, header = FALSE,
check.names = FALSE)})
# add source pdb column
result_files_df <- addpdbcol(result_files_df)
#i think each file now has its own dataframe. now we combine them
combined_results_df <- do.call("rbind", lapply(result_files_df, as.data.frame))
#@ line 981 (w/ orig PDBs, get an enormous volume. can either throw out this header, or filter as below)
# combined_results_df is now the final output of this section and the primary df
# 2. Volume Data ------------------------------------------
# get only the REAL, INDIV VOLUMES ACQUIRED!!!
# remove the sum volume
combined_results_df %>%
filter(grepl('[?]', V1)) -> combined_results_df
# acquire only the numeric data
combined_results_df %>%
separate(V1, c(NA ,"volume_data"), "volume = ") -> volume_data_df
# 3. Filter ------------
# remove the NA values from the dataframe (this is a result of rows that did not contain volume data)
volume_data_clean <- na.omit(volume_data_df)
volume_data_df <- volume_data_clean
# shit was imported from the text file as strings, convert to numbers
volume_data_df$volume_data <- as.numeric(as.character(volume_data_df$volume_data))
# remove outliers ----------
# outlier operation however FUCKS IT UP so... need to convert back to df in between ops
# therefore, below code filters >50, conv back to df, filter <= 1000, conv back to df
volume_data_df <- volume_data_df[volume_data_df$volume_data >= 50, ]
volume_data_df <- as.data.frame(volume_data_df)
#volume_data_df <- volume_data_df[volume_data_df$volume_data <= 1000, ]
#volume_data_df <- as.data.frame(volume_data_df)
# selecting only the max for each row
volume_data_df %>%
group_by(PDB_ID) %>% slice(which.max(volume_data)) -> max_volume_df
##group %>% group_by(sub) %>% slice(which.max(marks))
# from: https://www.geeksforgeeks.org/how-to-select-row-with-maximum-value-in-each-group-in-r-language/
# 4. VOLUME DATA PLOT! -----------------
# moved to main!
# hist(volume_data_df$volume_data,
#      main = "Distribution of Volume of Pockets",
#      xlab = "Volume, A3",
#      col = "darkmagenta",
#      xlim = c(50,600), #force start at 50 then go to 1000
#      #breaks = c(0,100,150,200,250,300,350,400,450,1000)
#      )
#
#
# 99. Cleanup! ----------
# rm(result_files_df,
#    combined_results_df,
#    temp_df,
#    volume_data_clean,
#    no_quest,
#    line_w_code
#
# )
# return data ----------
#return stuff ----------
volumeDataframes <- list(
"allVolDf" = volume_data_df,
"maxVolDf" = max_volume_df
)
# return(volumeDataframes)
#return(max_volume_df)
#}
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {read.delim(file = x, header = FALSE,
check.names = FALSE)})
#set working directory to the folder w files!
#setwd("~/heme-binding/results/volume")
setwd(activeResultPath)
# import all the shit that's been processed
# currently using results specific file, all of type .txt; therefore:
result_files_ls <- list.files(pattern = "*.txt")
activeResultPath
#activeResultPath
# may need to add path = whatever from wd into the parentheses
# result_files_ls is now a list of all the fuckin txt files
result_files_ls
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {read.delim(file = x, header = FALSE,
check.names = FALSE)})
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE)})
library(dplyr)
library(data.table)
library(tidyr)
library(ggplot2) #thus far not used 22 June 2021
source("~/heme-binding/scripts/r/addpdbcol.R")
#volumeFn <- function(activeLigand, activeResultPath)
#{
activeLigand = "HEM"
#for filtering: https://www.youtube.com/watch?v=PsSqn0pxouM
paste(activeLigand,"Volume data processing...")
# 0. Notes on global variables...---------------------------
#may need to specify this option every run/change for running ALL PROCESSED FILES
#options(max.print = 999999999999999999999) #or whatever number
# 1. Assembling all results into one dataframe -----------------------------
#set working directory to the folder w files!
#setwd("~/heme-binding/results/volume")
setwd(activeResultPath)
# import all the shit that's been processed
# currently using results specific file, all of type .txt; therefore:
result_files_ls <- list.files(pattern = "*.txt")
#activeResultPath
# may need to add path = whatever from wd into the parentheses
# result_files_ls is now a list of all the fuckin txt files
result_files_ls
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE)})
# add source pdb column
result_files_df <- addpdbcol(result_files_df)
#i think each file now has its own dataframe. now we combine them
combined_results_df <- do.call("rbind", lapply(result_files_df, as.data.frame))
#@ line 981 (w/ orig PDBs, get an enormous volume. can either throw out this header, or filter as below)
# combined_results_df is now the final output of this section and the primary df
# 2. Volume Data ------------------------------------------
# get only the REAL, INDIV VOLUMES ACQUIRED!!!
# remove the sum volume
combined_results_df %>%
filter(grepl('[?]', V1)) -> combined_results_df
# acquire only the numeric data
combined_results_df %>%
separate(V1, c(NA ,"volume_data"), "volume = ") -> volume_data_df
# 3. Filter ------------
# remove the NA values from the dataframe (this is a result of rows that did not contain volume data)
volume_data_clean <- na.omit(volume_data_df)
volume_data_df <- volume_data_clean
# shit was imported from the text file as strings, convert to numbers
volume_data_df$volume_data <- as.numeric(as.character(volume_data_df$volume_data))
# remove outliers ----------
# outlier operation however FUCKS IT UP so... need to convert back to df in between ops
# therefore, below code filters >50, conv back to df, filter <= 1000, conv back to df
volume_data_df <- volume_data_df[volume_data_df$volume_data >= 50, ]
volume_data_df <- as.data.frame(volume_data_df)
#volume_data_df <- volume_data_df[volume_data_df$volume_data <= 1000, ]
#volume_data_df <- as.data.frame(volume_data_df)
# selecting only the max for each row
volume_data_df %>%
group_by(PDB_ID) %>% slice(which.max(volume_data)) -> max_volume_df
##group %>% group_by(sub) %>% slice(which.max(marks))
# from: https://www.geeksforgeeks.org/how-to-select-row-with-maximum-value-in-each-group-in-r-language/
# 4. VOLUME DATA PLOT! -----------------
# moved to main!
# hist(volume_data_df$volume_data,
#      main = "Distribution of Volume of Pockets",
#      xlab = "Volume, A3",
#      col = "darkmagenta",
#      xlim = c(50,600), #force start at 50 then go to 1000
#      #breaks = c(0,100,150,200,250,300,350,400,450,1000)
#      )
#
#
# 99. Cleanup! ----------
# rm(result_files_df,
#    combined_results_df,
#    temp_df,
#    volume_data_clean,
#    no_quest,
#    line_w_code
#
# )
# return data ----------
#return stuff ----------
volumeDataframes <- list(
"allVolDf" = volume_data_df,
"maxVolDf" = max_volume_df
)
# return(volumeDataframes)
#return(max_volume_df)
#}
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE)})
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE)})
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE)})
# import all the shit that's been processed
# currently using results specific file, all of type .txt; therefore:
result_files_ls <- list.files(pattern = "*.txt")
#activeResultPath
# may need to add path = whatever from wd into the parentheses
# result_files_ls is now a list of all the fuckin txt files
result_files_ls
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE)})
# import all the shit that's been processed
# currently using results specific file, all of type .txt; therefore:
result_files_ls <- list.files(pattern = "*.txt")
#activeResultPath
# may need to add path = whatever from wd into the parentheses
# result_files_ls is now a list of all the fuckin txt files
result_files_ls
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE)})
# import all the shit that's been processed
# currently using results specific file, all of type .txt; therefore:
result_files_ls <- list.files(pattern = "*.txt")
#activeResultPath
# may need to add path = whatever from wd into the parentheses
# result_files_ls is now a list of all the fuckin txt files
result_files_ls
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE, fileEncoding = "UTF-8")})
# add source pdb column
result_files_df <- addpdbcol(result_files_df)
# import all the shit that's been processed
# currently using results specific file, all of type .txt; therefore:
result_files_ls <- list.files(pattern = "*.txt")
#activeResultPath
# may need to add path = whatever from wd into the parentheses
# result_files_ls is now a list of all the fuckin txt files
result_files_ls
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE, fileEncoding = "UTF-8")})
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE, fileEncoding = "UTF-8-BOM")})
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE, fileEncoding = "UTF-8-BOM")})
rrrrr <- lapply(result_files_ls, function(y) {data.table::fread(file = x)
rrrrr <- lapply(result_files_ls, function(y) {data.table::fread(file = x)})
rrrrr <- lapply(result_files_ls, function(y) {data.table::fread(file = y)})
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE, fileEncoding = "UTF-8",comment.char ="[[:alpha:]]")})
View(result_files_df)
View(result_files_df)
#activeResultPath
# may need to add path = whatever from wd into the parentheses
# result_files_ls is now a list of all the fuckin txt files
result_files_ls
# now read them from the list into a dataframe
result_files_df <- lapply(result_files_ls, function(x) {print (x)
read.delim(file = x, header = FALSE,check.names = FALSE, fileEncoding = "UTF-8",comment.char ="[[:alpha:]]")})
#rrrrr <- lapply(result_files_ls, function(y) {data.table::fread(file = y)})
# add source pdb column
result_files_df <- addpdbcol(result_files_df)
#i think each file now has its own dataframe. now we combine them
combined_results_df <- do.call("rbind", lapply(result_files_df, as.data.frame))
